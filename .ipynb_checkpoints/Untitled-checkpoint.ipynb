{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae5dd33c-ca80-438d-8b3d-bdf65a27e4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "import re\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "f74d0ed9-077b-495a-bca2-cb0b61fc1d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "OHCO = ['artist', 'title', 'verse_num', 'line_num', 'token_num']\n",
    "songs = [song for song in sorted(glob('data/*.txt'))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e294258-0641-4f96-9fc3-0096f24325b4",
   "metadata": {},
   "source": [
    "## Create LIB and DOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "id": "47a16dec-0cf0-47e7-ab92-ab2963e5f1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildLIBDOC(songs, OHCO=OHCO):\n",
    "    lib = []\n",
    "    doc = []\n",
    "    \n",
    "    for song in songs:\n",
    "        \n",
    "        # get artist and title\n",
    "        artist, title = song[5:-4].split('_')\n",
    "        \n",
    "        # import song  lyrics\n",
    "        df = pd.DataFrame(open(song, 'r', encoding='utf-8').readlines(), columns=['line'])\n",
    "        \n",
    "        # assign verse numbers\n",
    "        verse_stop = df.line.str.match('\\n| ')\n",
    "        verse_num = [i+1 for i in range(df.loc[verse_stop].shape[0])]\n",
    "        df.loc[verse_stop, 'verse_num'] = verse_num\n",
    "        try:\n",
    "            df.verse_num = df.verse_num.bfill().fillna(verse_num[-1:][0]+1)\n",
    "        except:\n",
    "            df.verse_num = 1\n",
    "        df = df.replace('\\n','')\n",
    "        df = df.loc[-(df.line == '')]\n",
    "        df['line'] = df['line'].str.strip()\n",
    "        \n",
    "        df['line'] = df['line'].apply(lambda x: re.sub(r'[^A-Za-z0-9]+', '', x))\n",
    "\n",
    "        # group together, assign new index\n",
    "        df = df.groupby(OHCO[2:3]).line.apply(lambda x: '\\n'.join(x)).to_frame()\n",
    "        df['title'] = title  \n",
    "        df['artist'] = artist  \n",
    "        df = df.reset_index().set_index(OHCO[:3]).rename(columns={'line':'verse'})\n",
    "        \n",
    "        lib.append((artist, title, song))\n",
    "        doc.append(df)\n",
    "        \n",
    "    DOC = pd.concat(doc)\n",
    "    LIB = pd.DataFrame(lib, columns=['artist', 'title', 'song_file']).set_index('artist')\n",
    "    return LIB, DOC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13e97d4-1f85-4585-83a7-02cbf66f1f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "LIB, DOC = buildLIBDOC(songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6201a3-433c-43e8-80a7-39e04428415c",
   "metadata": {},
   "source": [
    "## Create TOKEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "1184ebc7-1dc6-46f1-bff5-d2eae66d7d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DOC.verse.apply(lambda x: pd.Series(x.split('\\n'))).stack().to_frame().rename(columns={0:'line'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "71322632-d80d-43a5-bf74-022c754b12b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cschr\\AppData\\Local\\Temp/ipykernel_18100/3893052490.py:1: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  df = df.line.apply(lambda x: pd.Series(nltk.pos_tag(nltk.word_tokenize(x)))).stack().to_frame()\n"
     ]
    }
   ],
   "source": [
    "df = df.line.apply(lambda x: pd.Series(nltk.pos_tag(nltk.word_tokenize(x)))).stack().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "id": "c9632225-c9c1-4dd4-9448-f60504a3e8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={0:'temp'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "20cf0727-1b54-4a9b-b238-1c712c88eacd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist    title         verse_num        \n",
       "50 Cent   21 Questions  1.0        0   0      (New, NNP)\n",
       "                                       1     (York, NNP)\n",
       "                                       2     (City, NNP)\n",
       "                                   1   0      (You, PRP)\n",
       "                                       1      (are, VBP)\n",
       "                                                ...     \n",
       "Yung Joc  â€™Bout It      7.0        23  8     ('bout, IN)\n",
       "                                       9       (it, PRP)\n",
       "                                       10         ((, ()\n",
       "                                       11    (Woah, NNP)\n",
       "                                       12         (), ))\n",
       "Name: temp, Length: 2005906, dtype: object"
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.temp#.str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ddadeb-1eff-467b-b15a-1d0c5a70f30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildTOKEN(doc, OHCO=OHCO):\n",
    "    \n",
    "    # Convert verses to lines\n",
    "    df = doc.verse.apply(lambda x: pd.Series(x.split('\\n'))).stack().to_frame()\n",
    "    df = df.rename(columns={0:'line'})\n",
    "    \n",
    "    # Convert sentences to tokens\n",
    "    df = df.line.apply(lambda x: pd.Series(nltk.pos_tag(nltk.word_tokenize(x)))).stack().to_frame()\n",
    "    df = df.rename(columns={0:'temp'})\n",
    "    df['pos'] = df['temp'].apply(lambda x: x[1])\n",
    "    \n",
    "    #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec4436f-3bc8-4248-a9ca-3b5862c0fc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc_df, OHCO=OHCO, remove_pos_tuple=False, ws=False):\n",
    "    \n",
    "    # Paragraphs to Sentences\n",
    "    df = doc_df.para_str\\\n",
    "        .apply(lambda x: pd.Series(nltk.sent_tokenize(x)))\\\n",
    "        .stack()\\\n",
    "        .to_frame()\\\n",
    "        .rename(columns={0:'sent_str'})\n",
    "    \n",
    "    # Sentences to Tokens\n",
    "    # Local function to pick tokenizer\n",
    "    def word_tokenize(x):\n",
    "        if ws:\n",
    "            s = pd.Series(nltk.pos_tag(nltk.WhitespaceTokenizer().tokenize(x)))\n",
    "        else:\n",
    "            s = pd.Series(nltk.pos_tag(nltk.word_tokenize(x)))\n",
    "        return s\n",
    "            \n",
    "    df = df.sent_str\\\n",
    "        .apply(word_tokenize)\\\n",
    "        .stack()\\\n",
    "        .to_frame()\\\n",
    "        .rename(columns={0:'pos_tuple'})\n",
    "    \n",
    "    # Grab info from tuple\n",
    "    df['pos'] = df.pos_tuple.apply(lambda x: x[1])\n",
    "    df['token_str'] = df.pos_tuple.apply(lambda x: x[0])\n",
    "    if remove_pos_tuple:\n",
    "        df = df.drop('pos_tuple', 1)\n",
    "    \n",
    "    # Add index\n",
    "    df.index.names = OHCO\n",
    "    \n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
